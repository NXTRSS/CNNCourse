{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scSwrxuPDppz"
   },
   "source": [
    " # Computer Vision, 2\n",
    "\n",
    "\n",
    "***WAŻNE*** \n",
    "\n",
    "Jeśli używsz Colaba pamiętaj o włączeniu akceleracji GPU! Środowisko wykonawcze -> Zmień typ środowiska wykonawczego -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1yoipSyhXqW6",
    "outputId": "be1f353c-1387-4700-d9bf-e2773b466a66"
   },
   "outputs": [],
   "source": [
    "#poniższa komórka tylko dla Colaba\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PkTqqFYEU9p"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDEwSDQ9W6f9"
   },
   "source": [
    "# MLP for Computer Vision MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "EZyxyo0zW6f_",
    "outputId": "06a489b9-8658-4ce1-e14e-beef3056efe5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print('Training data shape : ', train_x.shape, train_y.shape)\n",
    "print('Testing data shape : ', test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(train_y)\n",
    "classes_num = len(classes)\n",
    "print('Total number of outputs : ', classes_num)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_x[0,:,:], cmap='copper')\n",
    "plt.title(\"Ground Truth : {}\".format(train_y[0]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_x[0,:,:], cmap='copper')\n",
    "plt.title(\"Ground Truth : {}\".format(test_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8eht9O8W6gB"
   },
   "outputs": [],
   "source": [
    "#Proszę zmienić macierz reprezentującą zdjęcia na wektor, jakiego będzie rozmiaru?\n",
    "train_x = None\n",
    "test_x = None\n",
    "\n",
    "#Podzielić wartości pikseli tak aby były z przedziału 0-1\n",
    "train_x = None\n",
    "test_x = None\n",
    "\n",
    "# Proszę skorzystać z gotowej funkcji do zamiany flag na wektor, który będzie zgodny z wyjściem z sieci\n",
    "train_y_one_hot = None\n",
    "test_y_one_hot = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRUKgzS5W6gC"
   },
   "outputs": [],
   "source": [
    "# Make a model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "#stworzenie modelu\n",
    "model = Sequential()\n",
    "#warstwa gęsta, 512 neuronów, funkcja aktywacji relu, proszę zadeklarować odpowiedni rozmiar wejścia\n",
    "None\n",
    "\n",
    "#warstwa gęsta, 512 neuronów, funkcja aktywacji relu\n",
    "None\n",
    "\n",
    "#warstwa gęsta z odpowiednią liczbą wyjścia, funkcja aktywacji softmax\n",
    "None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skompilowanie modelu:\n",
    "    #optimizer rmsprop\n",
    "    #odpowiedni błąd, zgodny z wyjściem softmax z modelu\n",
    "    #metryka do śledzenia: dokładność\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frp6p2BwW6gC",
    "outputId": "3de9cbaa-e04d-4923-c62b-43bd3f5563ff"
   },
   "outputs": [],
   "source": [
    "#trenowanie modelu. Proszę podać odpowiednie dane uczące, ustawić wielkosć batcha na 256\n",
    "#liczbę epok na 10, odpowiednie dane do walidacji oraz callback early_stopping_monitor (verbose na True)\n",
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuNJHqSsW6gD",
    "outputId": "a31382b1-f446-4fcb-dec1-12b8bbbdc52b"
   },
   "outputs": [],
   "source": [
    "[test_loss, test_acc] = model.evaluate(test_x, test_y_one_hot)\n",
    "print(f\"Evaluation result on Test Data : Loss = {test_loss}, accuracy = {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVuGAx-YW6gG"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    #Plot the Loss Curves\n",
    "    plt.figure(figsize=[8,6])\n",
    "    plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "    plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "    plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "    plt.xlabel('Epochs ',fontsize=16)\n",
    "    plt.ylabel('Loss',fontsize=16)\n",
    "    plt.title('Loss Curves',fontsize=16)\n",
    "    \n",
    "    #Plot the Accuracy Curves\n",
    "    plt.figure(figsize=[8,6]) \n",
    "    plt.plot(history.history['accuracy'], 'r', linewidth=3.0) \n",
    "    plt.plot(history.history['val_accuracy'], 'b',linewidth=3.0) \n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18) \n",
    "    plt.xlabel('Epochs ',fontsize=16) \n",
    "    plt.ylabel('Accuracy',fontsize=16) \n",
    "    plt.title('Accuracy Curves',fontsize=16)\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qBb5U6wW6gI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_GY4bt8NjTK"
   },
   "source": [
    "# MLP for Computer Vision CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOiET4g_WPaJ",
    "outputId": "775d0514-9517-427b-f89c-182e7982886c"
   },
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print('X_train: ' + str(train_x.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_x.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "VE3GpzHpEaSS",
    "outputId": "793b0370-fca4-40fd-f7e0-40392244444d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print('Training data shape : ', train_x.shape, train_y.shape)\n",
    "\n",
    "print('Testing data shape : ', test_x.shape, test_y.shape)\n",
    "\n",
    "\n",
    "classes = np.unique(train_y)\n",
    "classes_num = len(classes)\n",
    "\n",
    "\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(train_x[i])\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yy7Nf6TfGaKe"
   },
   "outputs": [],
   "source": [
    "#Proszę zmienić macierz reprezentującą zdjęcia na wektor, jakiego będzie rozmiaru?\n",
    "\n",
    "train_x = None\n",
    "test_x = None\n",
    "\n",
    "#Podzielić wartości pikseli tak aby były z przedziału 0-1\n",
    "train_x = None\n",
    "test_x = None\n",
    "\n",
    "# Proszę skorzystać z gotowej funkcji do zamiany flag na wektor, który będzie zgodny z wyjściem z sieci\n",
    "train_y_one_hot = None\n",
    "test_y_one_hot = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7fjUjc-Im3m"
   },
   "outputs": [],
   "source": [
    "# Make a model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "#stworzenie modelu\n",
    "model = Sequential()\n",
    "#warstwa gęsta, 512 neuronów, funkcja aktywacji relu, proszę zadeklarować odpowiedni rozmiar wejścia\n",
    "None\n",
    "\n",
    "#warstwa gęsta, 512 neuronów, funkcja aktywacji relu\n",
    "None\n",
    "\n",
    "#warstwa gęsta z odpowiednią liczbą wyjścia, funkcja aktywacji softmax\n",
    "None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skompilowanie modelu:\n",
    "    #optimizer rmsprop\n",
    "    #odpowiedni błąd, zgodny z wyjściem softmax z modelu\n",
    "    #metryka do śledzenia: dokładność\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frp6p2BwW6gC",
    "outputId": "3de9cbaa-e04d-4923-c62b-43bd3f5563ff"
   },
   "outputs": [],
   "source": [
    "#trenowanie modelu. Proszę podać odpowiednie dane uczące, ustawić wielkosć batcha na 256\n",
    "#liczbę epok na 30, odpowiednie dane do walidacji (verbose na True)\n",
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0Dq98-sJNV-",
    "outputId": "61250774-29dd-4680-95f6-b23120159273"
   },
   "outputs": [],
   "source": [
    "[test_loss, test_acc] = model.evaluate(test_x, test_y_one_hot)\n",
    "print(f\"Evaluation result on Test Data : Loss = {test_loss}, accuracy = {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibyF5ReEJwLd"
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrvJzLzMXOW8"
   },
   "source": [
    "# First CNN for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DqTsYH7XWBE"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = keras.datasets.cifar10.load_data()\n",
    "classes = np.unique(train_y)\n",
    "classes_num = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podzielić wartości pikseli tak aby były z przedziału 0-1\n",
    "train_x = None\n",
    "test_x = None\n",
    "\n",
    "# Proszę skorzystać z gotowej funkcji do zamiany flag na wektor, który będzie zgodny z wyjściem z sieci\n",
    "train_y_one_hot = None\n",
    "test_y_one_hot = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G38vm4FkcXDz"
   },
   "outputs": [],
   "source": [
    "#Tworzenie modelu\n",
    "model = Sequential()\n",
    "\n",
    "#warstwa konwolucyjna z 32 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same i odpowiednim kształem wejścia\n",
    "None\n",
    "#warstwa konwolucyjna z 32 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same\n",
    "None\n",
    "#warstwa MaxPooling2D o filtrze 2x2\n",
    "None\n",
    "\n",
    "#warstwa konwolucyjna z 64 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same \n",
    "None\n",
    "#warstwa konwolucyjna z 64 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same\n",
    "None\n",
    "#warstwa MaxPooling2D o filtrze 2x2\n",
    "None\n",
    "\n",
    "#warstwa konwolucyjna z 128 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same \n",
    "None\n",
    "#warstwa konwolucyjna z 128 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same\n",
    "None\n",
    "#warstwa MaxPooling2D o filtrze 2x2\n",
    "None\n",
    "\n",
    "#warstwa Flatten - ściągnięcie z macierzy do wektora\n",
    "None\n",
    "#warstwa gęsta, 128 neuronów, funkcja aktywacji relu i inicjalizacją he_uniform\n",
    "None\n",
    "#warstwa gęsta z odpowiednią liczbą neuronów na wyjściu, funkcja aktywacji softmax\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6V_lX43ZoOn"
   },
   "outputs": [],
   "source": [
    "\n",
    "#skompilowanie modelu:\n",
    "    #optimizer SGD z krokiem uczenia 0.001 i momentum 0.9\n",
    "    #odpowiedni błąd, zgodny z wyjściem softmax z modelu\n",
    "    #metryka do śledzenia: dokładność\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taloSXX5ZwW_"
   },
   "outputs": [],
   "source": [
    "#trenowanie modelu. Proszę podać odpowiednie dane uczące, ustawić wielkosć batcha na 64\n",
    "#liczbę epok na 30, odpowiednie dane do walidacji (verbose na True)\n",
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "_, acc = model.evaluate(test_x, test_y_one_hot, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z16DS3XpbMpP"
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9pBdccheCHX"
   },
   "source": [
    "# CNN with BN i Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1zTRfZ8enIv"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "#Tworzenie modelu\n",
    "model = Sequential()\n",
    "\n",
    "#warstwa konwolucyjna z 32 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same i odpowiednim kształem wejścia\n",
    "None\n",
    "#warstwa BatchNormalization\n",
    "None\n",
    "#warstwa konwolucyjna z 32 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same\n",
    "None\n",
    "#warstwa BatchNormalization\n",
    "None\n",
    "#warstwa MaxPooling2D o filtrze 2x2\n",
    "None\n",
    "#warstwa Dropout z prawdopodobieństwem odrzucenia 0.2\n",
    "None\n",
    "\n",
    "#warstwa konwolucyjna z 64 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same \n",
    "None\n",
    "#warstwa BatchNormalization\n",
    "None\n",
    "#warstwa konwolucyjna z 64 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same\n",
    "None\n",
    "#warstwa BatchNormalization\n",
    "None\n",
    "#warstwa MaxPooling2D o filtrze 2x2\n",
    "None\n",
    "#warstwa Dropout z prawdopodobieństwem odrzucenia 0.3\n",
    "None\n",
    "\n",
    "#warstwa konwolucyjna z 128 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same \n",
    "None\n",
    "#warstwa BatchNormalization\n",
    "None\n",
    "#warstwa konwolucyjna z 128 neuronami, filtrem 3x3, aktywacją relu, inicjalizacją he_uniform, pading same\n",
    "None\n",
    "#warstwa BatchNormalization\n",
    "None\n",
    "#warstwa MaxPooling2D o filtrze 2x2\n",
    "None\n",
    "#warstwa Dropout z prawdopodobieństwem odrzucenia 0.4\n",
    "None\n",
    "\n",
    "#warstwa Flatten - ściągnięcie z macierzy do wektora\n",
    "None\n",
    "#warstwa gęsta, 128 neuronów, funkcja aktywacji relu i inicjalizacją he_uniform\n",
    "None\n",
    "#warstwa BatchNormalization\n",
    "None\n",
    "#warstwa Dropout z prawdopodobieństwem odrzucenia 0.3\n",
    "None\n",
    "#warstwa gęsta z odpowiednią liczbą neuronów na wyjściu, funkcja aktywacji softmax\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6V_lX43ZoOn"
   },
   "outputs": [],
   "source": [
    "\n",
    "#skompilowanie modelu:\n",
    "    #optimizer SGD z krokiem uczenia 0.001 i momentum 0.9\n",
    "    #odpowiedni błąd, zgodny z wyjściem softmax z modelu\n",
    "    #metryka do śledzenia: dokładność\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taloSXX5ZwW_"
   },
   "outputs": [],
   "source": [
    "#trenowanie modelu. Proszę podać odpowiednie dane uczące, ustawić wielkosć batcha na 64\n",
    "#liczbę epok na 30, odpowiednie dane do walidacji (verbose na True)\n",
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "_, acc = model.evaluate(test_x, test_y_one_hot, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z16DS3XpbMpP"
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QV3mFV1uVnU"
   },
   "source": [
    "# Sesja samodzielna\n",
    "\n",
    "Stwórz własną sieć konwolucyjną, której zadaniem będzie klasyfikacja obrazków pochodzących ze zbioru CIFAR100\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "Pamiętaj, by w dodać GPU w ustawieniach środowiska wykonawczego\n",
    "Wynikiem podziel się na slacku, niech wygra najlepszy! ;)\n",
    "\n",
    "Do zbadania:\n",
    "\n",
    "\n",
    "*   Optymalna ilość warstw, jak wpływają na działanie warstwy DropOut i BatchNormalization?\n",
    "*   Rodzaje filtrów\n",
    "*   Hiperparametry dotyczące uczenia sieci\n",
    "*   Optymalna ilość epok\n",
    "*   Wybór optimizera\n",
    "*   Sposób inicjalizacji wag\n",
    "\n",
    "\n",
    "> Polecam nie szukać gotowych rozwiązań ;)\n",
    "\n",
    "Poniżej kilka podpowiedzi:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rr4P3LepTN2S"
   },
   "source": [
    "# Podpowiedzi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qs0tS1TSHLj"
   },
   "source": [
    "1. Pobranie bazy danychw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B69MzbpRR9sM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8r46e7kATJ5m"
   },
   "source": [
    "2. Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFwE9PB_TJqg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9XuagTCUhq5"
   },
   "source": [
    "3. Sprawdzenie zawartości danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J35ic5ALTtOX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FSybHjjUpVe"
   },
   "source": [
    "4. Proste konwolucje\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwghaCxZUo0s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-xuUT7nVCC3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQeIA0oLVzsV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlCKUh7AXN0c"
   },
   "source": [
    "Link do benchmarka\n",
    "\n",
    "https://paperswithcode.com/sota/image-classification-on-cifar-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmgRaza6pTXr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "yrvJzLzMXOW8",
    "f9pBdccheCHX",
    "5ik0uB8el6SE",
    "2QV3mFV1uVnU",
    "rr4P3LepTN2S"
   ],
   "name": "cv_day_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
